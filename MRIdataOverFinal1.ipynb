{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb19c578-1075-45d9-a8ad-c02539a2b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found: TRAIN\n",
      "✅ Found: VAL\n",
      "✅ Found: TEST\n",
      "✅ Dataset structure verified. Now ready for image processing!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define dataset root path\n",
    "dataset_path = r\"C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\"\n",
    "\n",
    "# Define processed image paths\n",
    "processed_folder = os.path.join(dataset_path, \"Processed_Images\")\n",
    "image_folder = os.path.join(processed_folder, \"images\")\n",
    "mask_folder = os.path.join(processed_folder, \"masks\")\n",
    "\n",
    "# ✅ Create necessary directories if they don’t exist\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "os.makedirs(mask_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Verify dataset structure\n",
    "folders = [\"TRAIN\", \"VAL\", \"TEST\"]\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"✅ Found: {folder}\")\n",
    "    else:\n",
    "        print(f\"❌ Missing: {folder}\")\n",
    "\n",
    "print(\"✅ Dataset structure verified. Now ready for image processing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf53a1f-e570-4e76-b79e-497023a7ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All original images saved in: C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\original\n",
      "✅ All overlay images saved in: C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\overlay\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "\n",
    "# ✅ Define dataset directories\n",
    "dataset_path = r\"C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\"\n",
    "processed_folder = os.path.join(dataset_path, \"Processed_Images\")\n",
    "original_folder = os.path.join(processed_folder, \"original\")\n",
    "overlay_folder = os.path.join(processed_folder, \"overlay\")\n",
    "\n",
    "# ✅ Create folders if they don’t exist\n",
    "os.makedirs(original_folder, exist_ok=True)\n",
    "os.makedirs(overlay_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Load annotation JSON\n",
    "annotation_file = os.path.join(dataset_path, \"annotations_all.json\")\n",
    "\n",
    "with open(annotation_file, \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# ✅ Function to create mask from annotation\n",
    "def create_mask_from_annotation(annotation, original_size):\n",
    "    h_orig, w_orig = original_size  \n",
    "    mask = np.zeros((h_orig, w_orig), dtype=np.uint8)\n",
    "    contour_list = []\n",
    "\n",
    "    for region in annotation[\"regions\"]:\n",
    "        shape_attr = region[\"shape_attributes\"]\n",
    "        \n",
    "        if shape_attr[\"name\"] == \"polygon\":\n",
    "            all_x = np.array(shape_attr[\"all_points_x\"])\n",
    "            all_y = np.array(shape_attr[\"all_points_y\"])\n",
    "\n",
    "            all_x = np.clip(all_x, 0, w_orig - 1)\n",
    "            all_y = np.clip(all_y, 0, h_orig - 1)\n",
    "\n",
    "            contour = np.array(list(zip(all_x, all_y)), dtype=np.int32)\n",
    "            contour_list.append(contour)\n",
    "\n",
    "            # ✅ Draw the tumor mask properly\n",
    "            cv2.fillPoly(mask, [contour], 255)\n",
    "\n",
    "    return mask, contour_list\n",
    "\n",
    "# ✅ Process all images from TRAIN, TEST, and VAL folders\n",
    "for folder in [\"TRAIN\", \"TEST\", \"VAL\"]:\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "        # ✅ Check if it's a valid image\n",
    "        if not img_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"⚠️ Skipping {img_name}, unable to read.\")\n",
    "            continue\n",
    "\n",
    "        original_size = img.shape[:2]  \n",
    "\n",
    "        # ✅ Save original image\n",
    "        save_img(os.path.join(original_folder, img_name), np.expand_dims(img, axis=-1))\n",
    "\n",
    "        base_filename = os.path.splitext(img_name)[0]  \n",
    "        matching_key = next((key for key in annotations.keys() if base_filename in key), None)\n",
    "\n",
    "        if matching_key:\n",
    "            mask, contours = create_mask_from_annotation(annotations[matching_key], original_size)\n",
    "\n",
    "            # ✅ Fix color formatting\n",
    "            img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            # ✅ Create mask overlay\n",
    "            colored_mask = np.zeros_like(img_color)\n",
    "            colored_mask[:, :, 2] = mask  \n",
    "\n",
    "            # ✅ Blend overlay\n",
    "            overlayed_image = cv2.addWeighted(img_color, 1, colored_mask, 0.6, 0)\n",
    "\n",
    "            # ✅ Draw tumor boundary in **Blue**\n",
    "            cv2.polylines(overlayed_image, contours, isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "            # ✅ Add tumor label at correct position\n",
    "            if len(contours) > 0:\n",
    "                M = cv2.moments(contours[0])\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    cv2.putText(overlayed_image, \"Tumor Detected\", (cX - 10, cY - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 100, 10), 2, cv2.LINE_AA)\n",
    "\n",
    "            # ✅ Save overlay image\n",
    "            save_img(os.path.join(overlay_folder, img_name), overlayed_image)\n",
    "\n",
    "print(f\"✅ All original images saved in: {original_folder}\")\n",
    "print(f\"✅ All overlay images saved in: {overlay_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c97d9-58e8-4b75-98de-5816e6146b51",
   "metadata": {},
   "source": [
    "Processing All Images (Original + Overlayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c1ec3d-215a-4a82-8cc1-dd224493c781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All resized original images saved in: C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\final_original\n",
      "✅ All resized overlay images saved in: C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\final_overlay\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "\n",
    "# ✅ Define dataset directories\n",
    "processed_folder = os.path.join(dataset_path, \"Processed_Images\")\n",
    "original_folder = os.path.join(processed_folder, \"original\")\n",
    "overlay_folder = os.path.join(processed_folder, \"overlay\")\n",
    "final_original_folder = os.path.join(processed_folder, \"final_original\")\n",
    "final_overlay_folder = os.path.join(processed_folder, \"final_overlay\")\n",
    "\n",
    "# ✅ Create necessary directories\n",
    "os.makedirs(final_original_folder, exist_ok=True)\n",
    "os.makedirs(final_overlay_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Target size (256x256) - Ensuring consistency\n",
    "target_size = (256, 256)\n",
    "\n",
    "# ✅ Function to resize both images while preserving alignment\n",
    "def resize_pair(image, overlay, target_size):\n",
    "    image_resized = cv2.resize(image, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "    overlay_resized = cv2.resize(overlay, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "    return image_resized, overlay_resized\n",
    "\n",
    "# ✅ Process all images in the original and overlay folders\n",
    "for img_name in os.listdir(original_folder):\n",
    "    img_path = os.path.join(original_folder, img_name)\n",
    "    overlay_path = os.path.join(overlay_folder, img_name)\n",
    "\n",
    "    # ✅ Load images\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    overlay = cv2.imread(overlay_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None or overlay is None:\n",
    "        print(f\"⚠️ Skipping {img_name}, unable to read.\")\n",
    "        continue\n",
    "\n",
    "    # ✅ Resize both images together\n",
    "    img_resized, overlay_resized = resize_pair(img, overlay, target_size)\n",
    "\n",
    "    # ✅ Save resized images\n",
    "    save_img(os.path.join(final_original_folder, img_name), np.expand_dims(img_resized, axis=-1))\n",
    "    save_img(os.path.join(final_overlay_folder, img_name), np.expand_dims(overlay_resized, axis=-1))\n",
    "\n",
    "print(f\"✅ All resized original images saved in: {final_original_folder}\")\n",
    "print(f\"✅ All resized overlay images saved in: {final_overlay_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86c3bd22-50bd-47a7-8df1-16ffff2c869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All images resized and stored in:\n",
      "   📂 C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\resized_original\n",
      "   📂 C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\resized_overlays\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "\n",
    "# ✅ Define dataset directories\n",
    "base_folder = r\"C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\"\n",
    "processed_folder = os.path.join(base_folder, \"Processed_Images\")\n",
    "\n",
    "# ✅ Define paths for resized images\n",
    "resized_original_folder = os.path.join(processed_folder, \"resized_original\")\n",
    "resized_overlays_folder = os.path.join(processed_folder, \"resized_overlays\")\n",
    "\n",
    "# ✅ Define paths for final processed images\n",
    "final_images_folder = os.path.join(processed_folder, \"final_images\")\n",
    "final_original_folder = os.path.join(final_images_folder, \"images_resized_original\")\n",
    "final_masked_folder = os.path.join(final_images_folder, \"images_masked_overlays\")\n",
    "\n",
    "# ✅ Create necessary directories\n",
    "os.makedirs(resized_original_folder, exist_ok=True)\n",
    "os.makedirs(resized_overlays_folder, exist_ok=True)\n",
    "os.makedirs(final_original_folder, exist_ok=True)\n",
    "os.makedirs(final_masked_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Target size for all images\n",
    "img_size = (256, 256)\n",
    "\n",
    "# ✅ Function to resize images\n",
    "def resize_image(image_path, output_path, img_size, is_gray=True):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE if is_gray else cv2.IMREAD_COLOR)\n",
    "    if img is not None:\n",
    "        resized_img = cv2.resize(img, img_size)\n",
    "        save_img(output_path, np.expand_dims(resized_img, axis=-1) if is_gray else resized_img)\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Unable to load {image_path}\")\n",
    "\n",
    "# ✅ Resize original images\n",
    "original_folder = os.path.join(processed_folder, \"original\")\n",
    "for img_name in os.listdir(original_folder):\n",
    "    input_path = os.path.join(original_folder, img_name)\n",
    "    output_path = os.path.join(resized_original_folder, img_name)\n",
    "    resize_image(input_path, output_path, img_size, is_gray=True)\n",
    "\n",
    "# ✅ Resize overlay images\n",
    "overlay_folder = os.path.join(processed_folder, \"overlay\")\n",
    "for img_name in os.listdir(overlay_folder):\n",
    "    input_path = os.path.join(overlay_folder, img_name)\n",
    "    output_path = os.path.join(resized_overlays_folder, img_name)\n",
    "    resize_image(input_path, output_path, img_size, is_gray=False)\n",
    "\n",
    "print(f\"✅ All images resized and stored in:\")\n",
    "print(f\"   📂 {resized_original_folder}\")\n",
    "print(f\"   📂 {resized_overlays_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a90f0ddf-cb22-4aa8-aad3-62da82c02ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All binary masks generated and saved in: C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\masks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "\n",
    "# ✅ Define dataset directories\n",
    "base_folder = r\"C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\"\n",
    "processed_folder = os.path.join(base_folder, \"Processed_Images\")\n",
    "\n",
    "# ✅ Paths for images and masks\n",
    "original_folder = os.path.join(processed_folder, \"original\")  # Use ORIGINAL images\n",
    "masks_folder = os.path.join(processed_folder, \"masks\")  # ✅ Binary masks will be stored here\n",
    "\n",
    "# ✅ Create necessary directories\n",
    "os.makedirs(masks_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Load annotation JSON\n",
    "annotation_file = os.path.join(base_folder, \"annotations_all.json\")\n",
    "with open(annotation_file, \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# ✅ Function to create mask from annotation\n",
    "def create_mask_from_annotation(annotation, img_shape):\n",
    "    h_orig, w_orig = img_shape  # Get original image dimensions\n",
    "    mask = np.zeros((h_orig, w_orig), dtype=np.uint8)  # Black background\n",
    "\n",
    "    for region in annotation[\"regions\"]:\n",
    "        shape_attr = region[\"shape_attributes\"]\n",
    "        \n",
    "        if shape_attr[\"name\"] == \"polygon\":\n",
    "            all_x = np.array(shape_attr[\"all_points_x\"])\n",
    "            all_y = np.array(shape_attr[\"all_points_y\"])\n",
    "\n",
    "            # Ensure coordinates stay within the image bounds\n",
    "            all_x = np.clip(all_x, 0, w_orig - 1)\n",
    "            all_y = np.clip(all_y, 0, h_orig - 1)\n",
    "\n",
    "            # Convert points to contour format\n",
    "            contour = np.array(list(zip(all_x, all_y)), dtype=np.int32)\n",
    "\n",
    "            # ✅ Fill the tumor region with white (255)\n",
    "            cv2.fillPoly(mask, [contour], 255)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# ✅ Process all images from the original folder\n",
    "for img_name in os.listdir(original_folder):\n",
    "    img_path = os.path.join(original_folder, img_name)\n",
    "    mask_path = os.path.join(masks_folder, img_name)\n",
    "\n",
    "    # ✅ Load original image to get dimensions\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"⚠️ Skipping {img_name}, unable to read.\")\n",
    "        continue\n",
    "\n",
    "    # ✅ Extract corresponding annotation key\n",
    "    base_filename = os.path.splitext(img_name)[0]  \n",
    "    matching_key = next((key for key in annotations.keys() if base_filename in key), None)\n",
    "\n",
    "    if matching_key:\n",
    "        # ✅ Generate tumor mask\n",
    "        mask = create_mask_from_annotation(annotations[matching_key], img.shape)\n",
    "\n",
    "        # ✅ Save the generated binary mask\n",
    "        save_img(mask_path, np.expand_dims(mask, axis=-1))\n",
    "\n",
    "print(f\"✅ All binary masks generated and saved in: {masks_folder}\")\n",
    "# isse masking perfect ho raha hai with original size images ab bus isko resize krna hai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0e5face-d928-4930-9494-ffaab4697fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All resized masks stored in: C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\resized_masks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "\n",
    "# ✅ Paths for resized masks\n",
    "resized_masks_folder = os.path.join(processed_folder, \"resized_masks\")  # ✅ Final aligned masks\n",
    "os.makedirs(resized_masks_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Target size\n",
    "target_size = (256, 256)\n",
    "\n",
    "# ✅ Function to resize while preserving aspect ratio\n",
    "def resize_with_aspect_ratio(image, target_size, interpolation=cv2.INTER_NEAREST):\n",
    "    h, w = image.shape[:2]\n",
    "    target_w, target_h = target_size\n",
    "\n",
    "    # ✅ Compute scale to maintain aspect ratio\n",
    "    scale = min(target_w / w, target_h / h)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "\n",
    "    # ✅ Resize image\n",
    "    resized = cv2.resize(image, (new_w, new_h), interpolation=interpolation)\n",
    "\n",
    "    # ✅ Create a black canvas\n",
    "    final_image = np.zeros((target_h, target_w), dtype=np.uint8)\n",
    "\n",
    "    # ✅ Center the resized image on the black canvas\n",
    "    x_offset = (target_w - new_w) // 2\n",
    "    y_offset = (target_h - new_h) // 2\n",
    "    final_image[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized\n",
    "\n",
    "    return final_image\n",
    "\n",
    "# ✅ Resize masks while preserving aspect ratio\n",
    "masks_folder = os.path.join(processed_folder, \"masks\")  # Previously generated masks\n",
    "\n",
    "for mask_name in os.listdir(masks_folder):\n",
    "    mask_path = os.path.join(masks_folder, mask_name)\n",
    "    resized_mask_path = os.path.join(resized_masks_folder, mask_name)\n",
    "\n",
    "    # ✅ Load mask\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if mask is not None:\n",
    "        # ✅ Resize mask while maintaining aspect ratio\n",
    "        resized_mask = resize_with_aspect_ratio(mask, target_size)\n",
    "\n",
    "        # ✅ Save resized mask\n",
    "        save_img(resized_mask_path, np.expand_dims(resized_mask, axis=-1))\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Unable to read {mask_name}\")\n",
    "\n",
    "print(f\"✅ All resized masks stored in: {resized_masks_folder}\")\n",
    "# 256 by 256 pixels me properly resize ho chuka hai wo bhi perfectly aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea9d746a-1fff-4cbc-8117-a133ced98108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suraj Yadav\\AppData\\Local\\Temp\\ipykernel_14772\\2088412016.py:26: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
      "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Augmentation complete! Augmented images and masks saved in:\n",
      "   📂 C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\augmented_images\n",
      "   📂 C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\\augmented_masks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "\n",
    "# ✅ Define dataset directories\n",
    "processed_folder = r\"C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\"\n",
    "resized_original_folder = os.path.join(processed_folder, \"resized_original\")\n",
    "resized_mask_folder = os.path.join(processed_folder, \"resized_masks\")  # Binary Masks\n",
    "augmented_folder = os.path.join(processed_folder, \"augmented_images\")\n",
    "augmented_mask_folder = os.path.join(processed_folder, \"augmented_masks\")\n",
    "\n",
    "# ✅ Create necessary directories\n",
    "os.makedirs(augmented_folder, exist_ok=True)\n",
    "os.makedirs(augmented_mask_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Augmentation Pipeline (Ensuring tumor visibility)\n",
    "augment_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),  \n",
    "    A.VerticalFlip(p=0.5),  \n",
    "    A.RandomRotate90(p=0.5),  \n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.2),  \n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),  # Improve contrast\n",
    "    A.CLAHE(clip_limit=2, tile_grid_size=(8, 8), p=0.3),  # Local histogram equalization\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
    "    A.OneOf([\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.4),  # Adjust gamma\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1, p=0.3)  # Slight color change\n",
    "    ], p=0.3)\n",
    "], additional_targets={'mask': 'mask'})  # Ensure mask follows the same transformations\n",
    "\n",
    "# ✅ Function to Augment Image-Mask Pairs\n",
    "def augment_and_save(img, mask, img_name):\n",
    "    augmented = augment_pipeline(image=img, mask=mask)\n",
    "    aug_img, aug_mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "    # ✅ Save Augmented Images\n",
    "    save_img(os.path.join(augmented_folder, f\"aug_{img_name}\"), np.expand_dims(aug_img, axis=-1))\n",
    "    save_img(os.path.join(augmented_mask_folder, f\"aug_{img_name}\"), np.expand_dims(aug_mask, axis=-1))\n",
    "\n",
    "# ✅ Apply augmentation to all images and masks\n",
    "for img_name in os.listdir(resized_original_folder):\n",
    "    img_path = os.path.join(resized_original_folder, img_name)\n",
    "    mask_path = os.path.join(resized_mask_folder, img_name)\n",
    "\n",
    "    # ✅ Load image and mask\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None or mask is None:\n",
    "        print(f\"⚠️ Skipping {img_name}, unable to read.\")\n",
    "        continue\n",
    "\n",
    "    # ✅ Perform augmentation and save\n",
    "    augment_and_save(img, mask, img_name)\n",
    "\n",
    "print(f\"✅ Augmentation complete! Augmented images and masks saved in:\")\n",
    "print(f\"   📂 {augmented_folder}\")\n",
    "print(f\"   📂 {augmented_mask_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00a5072e-f456-43cf-b749-181369613966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train dataset: 640 images\n",
      "✅ Validation dataset: 80 images\n",
      "✅ Test dataset: 81 images\n",
      "✅ Dataset split complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ Define dataset paths\n",
    "processed_folder = r\"C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\"\n",
    "augmented_images_folder = os.path.join(processed_folder, \"augmented_images\")\n",
    "augmented_masks_folder = os.path.join(processed_folder, \"augmented_masks\")\n",
    "\n",
    "# ✅ Define paths for train, val, and test datasets\n",
    "train_folder = os.path.join(processed_folder, \"train\")\n",
    "val_folder = os.path.join(processed_folder, \"val\")\n",
    "test_folder = os.path.join(processed_folder, \"test\")\n",
    "\n",
    "# ✅ Create subdirectories for images and masks\n",
    "for split in [train_folder, val_folder, test_folder]:\n",
    "    os.makedirs(os.path.join(split, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split, \"masks\"), exist_ok=True)\n",
    "\n",
    "# ✅ Get list of augmented image files\n",
    "image_files = sorted(os.listdir(augmented_images_folder))\n",
    "\n",
    "# ✅ Ensure masks follow the correct naming pattern\n",
    "mask_files = sorted(os.listdir(augmented_masks_folder))\n",
    "\n",
    "# ✅ Ensure we only work with matching image-mask pairs\n",
    "image_files = [f for f in image_files if f in mask_files]\n",
    "\n",
    "# ✅ Split into train (80%), val (10%), and test (10%)\n",
    "train_files, test_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "val_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# ✅ Function to move files\n",
    "def move_files(file_list, src_img_folder, src_mask_folder, dest_folder):\n",
    "    for file_name in file_list:\n",
    "        img_src = os.path.join(src_img_folder, file_name)\n",
    "        mask_src = os.path.join(src_mask_folder, file_name)\n",
    "\n",
    "        img_dest = os.path.join(dest_folder, \"images\", file_name)\n",
    "        mask_dest = os.path.join(dest_folder, \"masks\", file_name)\n",
    "\n",
    "        # ✅ Check if files exist before copying\n",
    "        if not os.path.exists(img_src):\n",
    "            print(f\"⚠️ Missing Image: {img_src}\")\n",
    "            continue\n",
    "        if not os.path.exists(mask_src):\n",
    "            print(f\"⚠️ Missing Mask: {mask_src}\")\n",
    "            continue\n",
    "\n",
    "        shutil.copy(img_src, img_dest)\n",
    "        shutil.copy(mask_src, mask_dest)\n",
    "\n",
    "# ✅ Move files to respective sets\n",
    "move_files(train_files, augmented_images_folder, augmented_masks_folder, train_folder)\n",
    "move_files(val_files, augmented_images_folder, augmented_masks_folder, val_folder)\n",
    "move_files(test_files, augmented_images_folder, augmented_masks_folder, test_folder)\n",
    "\n",
    "# ✅ Verify dataset split\n",
    "train_img_count = len(os.listdir(os.path.join(train_folder, \"images\")))\n",
    "val_img_count = len(os.listdir(os.path.join(val_folder, \"images\")))\n",
    "test_img_count = len(os.listdir(os.path.join(test_folder, \"images\")))\n",
    "\n",
    "print(f\"✅ Train dataset: {train_img_count} images\")\n",
    "print(f\"✅ Validation dataset: {val_img_count} images\")\n",
    "print(f\"✅ Test dataset: {test_img_count} images\")\n",
    "print(f\"✅ Dataset split complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1e0eb49-7493-4531-a0d5-d3367c8ffe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset Loaded:\n",
      "   - Train: (640, 256, 256, 1), (640, 256, 256, 1)\n",
      "   - Validation: (80, 256, 256, 1), (80, 256, 256, 1)\n",
      "   - Test: (81, 256, 256, 1), (81, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# ✅ Define dataset directories\n",
    "processed_folder = r\"C:\\Users\\Suraj Yadav\\FinalProjectTest\\datasetMRI\\Br35H-Mask-RCNN\\Processed_Images\"\n",
    "\n",
    "train_images_path = os.path.join(processed_folder, \"train/images\")\n",
    "train_masks_path = os.path.join(processed_folder, \"train/masks\")\n",
    "\n",
    "val_images_path = os.path.join(processed_folder, \"val/images\")\n",
    "val_masks_path = os.path.join(processed_folder, \"val/masks\")\n",
    "\n",
    "test_images_path = os.path.join(processed_folder, \"test/images\")\n",
    "test_masks_path = os.path.join(processed_folder, \"test/masks\")\n",
    "\n",
    "# ✅ Function to Load Images & Masks\n",
    "def load_data(image_folder, mask_folder):\n",
    "    image_filenames = sorted(os.listdir(image_folder))\n",
    "    mask_filenames = sorted(os.listdir(mask_folder))\n",
    "\n",
    "    images, masks = [], []\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_folder, img_file)\n",
    "        mask_path = os.path.join(mask_folder, mask_file)\n",
    "\n",
    "        # ✅ Load images\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) / 255.0  # Normalize\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) / 255.0  # Normalize\n",
    "\n",
    "        # ✅ Expand dimensions for model input shape (256,256,1)\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# ✅ Load Train, Val, Test Data\n",
    "X_train, Y_train = load_data(train_images_path, train_masks_path)\n",
    "X_val, Y_val = load_data(val_images_path, val_masks_path)\n",
    "X_test, Y_test = load_data(test_images_path, test_masks_path)\n",
    "\n",
    "# ✅ Print dataset shapes\n",
    "print(f\"✅ Dataset Loaded:\")\n",
    "print(f\"   - Train: {X_train.shape}, {Y_train.shape}\")\n",
    "print(f\"   - Validation: {X_val.shape}, {Y_val.shape}\")\n",
    "print(f\"   - Test: {X_test.shape}, {Y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f884f7e2-861a-4a13-b12e-e1eec1801945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 512)  2097664     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 256)  524544      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 131200      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 128 147584      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 32832       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 1)  65          conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,030,593\n",
      "Trainable params: 31,030,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# ✅ Function to Build U-Net Model\n",
    "def build_unet(input_shape=(256, 256, 1)):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder (Contracting Path)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Decoder (Expanding Path)\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# ✅ Initialize U-Net Model\n",
    "unet_model = build_unet()\n",
    "unet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.MeanIoU(num_classes=2)]\n",
    ")\n",
    "\n",
    "# ✅ Print Model Summary\n",
    "unet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057e961-d1e6-4c7a-b0b8-02065c1e0eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c6902-bd80-4034-8d75-6fe9295e5e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f563d-887c-4e15-9731-efa7aa1d9ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32e456e5-1ce6-4036-a652-b313cb88af56",
   "metadata": {},
   "source": [
    "Splitting Dataset into Train/Val/Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
